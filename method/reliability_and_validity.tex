\section{Reliability and validity}
Reliability and validity are important topics within all types of research. 
These topics provide a basis for the discussion for whether we are measuring what we think we are measuring and whether these measures can be viewed as consistent and valid. 
Both within reliability and validity you can find several different concepts addressing different types of reliability and validity. 
One of example of this can be seen with validity where you often can see papers refer to internal consistency, interal validity or external validity etc.

\bigskip\noindent
This chapter will first present a short introduction to what reliability and validity are and some of the most common threats to these concepts.  
Though some factors relating to validity and reliability have already been mentioned in other chapters, 
we will include a concluding section about here. 
This is because these concepts can in various ways been seen as the linchpin of any experiment.

\subsection{Reliability}
	When talking about reliability we usually talk about the four key concepts, \textit{equivalence reliability}, \textit{stability reliability}, \textit{internal consistency} and  \textit{interrater reliability}. 
	Each estimating different construcys regarding how reliable a study is. 
	It is here important to mention that one can not measure reliability, but several strategies exist in order to attempt to estimate how reliable an experiment is.
	
	%\subsection{Equivalence reliability}
	\bigskip\noindent
	Equivalence reliability is the extent to which two items measure identical concepts at an identical level of difficulty (\cite{colostateReliability}). This is often measured as the correlation coefficient, measuring the strength of the correlation between the dependent variable and the independent variabel. 
	
	%\subsection{Stability reliability}
	\bigskip\noindent
	Stability reliability is a measure of the instruments stability, e.g how accurate an instrument is. To give an answer to this, one would usually repeat a given test to see if it gives the same results. A analysis with Cronbach's alpha between the first test and the second test can give an indicator to the stability of the test.
	
	%\subsection{Internal consistency}
	\bigskip\noindent
	Internal consistency is a measure of how well an instructument measures the same underlying concepts. A common way of measuring this is to use Cronbach's alpha between the items on a questionaire.
	
	%\subsection{Interrater reliability}
	\bigskip\noindent
	Interrater reliability is the extent to which raters agree, and is used as a measure of the rating system. Normally this is established by using a Cohen's kappa if there is only two raters, and Fleiss' kappa (\cite{gwet2001handbook}, \cite{shrout1979intraclass}).
	
\subsection{Validity}
	Validity assesses the degree of which an experiment and design measures the concept that the researchers intended to measure.
	When talking about validity, we usually talk about \textit{internal validity} and \textit{external validity}, each with its own subcategories like \textit{face validity}, \textit{construct validity} and \textit{content validity}.
	Internal validity refers to how the study was design, organized and conducted, and is important in order to say that an experiment
 accurately reflects the underlying concepts and constructs. 
External validity, on the other hand, is important because the results of an experiment doesn't mean much if it is only applicable for the population that participated(e.g. we want the results to be generalised and transferrable).
	We will not provide you with an exhaustive list of potensial threats to the validity of an experiment, but will here give a short overview over the most common ones.
	
	\subsubsection{Internal validity}
	Some of the threats that may threaten the internal validity of an experiment include \textit{testing effects}, \textit{selection bias}, \textit{experimental mortality} and \textit{diffusion between groups}.
	
	\bigskip\noindent
	The testing effects is an effect that can be present in any design which include multiple stages. 
	One example of this is the pretest-posttest design, where the results on the posttest can be influenced by the pretest in itself. 
	This can be because that the participants learned from completing the pretest and hence performed better on the posttest.
	
	\bigskip\noindent
	Selection bias can be another threat to the internal validity of an experiment and refers to differences between groups that may influence the results of the experiment. Though it is most prevalent in quasi-experimental design where the groups are not randomly assigned, it may occur in experimental design as well. 
	
	\bigskip\noindent
	Experimental mortality is a threat that refers to the fact that participants dropping out of the experiment for various reasons. This may become a real potensial threat in quasi-experimental design if you unintentionally created a group where the people were more likely to drop out of the experiment.
	
	\bigskip\noindent
	Diffusion between group refers to an effect where one of the group was effected by the other group. In most cases we are interested in the control group, and wether or not they have been affected by the experimental group. The "`contamination"' of the control group may happen in several different ways depending on how the experiment is done. 
	This effect can be seen as a umbrella-term for other threats involving cross-contamination between the groups (e.g. rivalry or demoralization).
	
	\subsubsection{External validity}
	Some threats to external validity have already been covered in the section about internal validity, \textit{selection bias} is one example of this. 
	Some of the more unique threats to external validity include the \textit{"`real-world"' versus "`experimental world"'} and \textit{"`faulty constructs"'} threats, where the first refers to when participants are aware that they are part of a study and may therefore alter their behaviour because of this, or that the environment in which the study is conducted influences the participants. The latter can be a bit more subtle in how it manifests itself, but refers to how well construct have been narrowed down from concepts, and how these constructs are measured.
	
	\bigskip\noindent
	The "`real world"' versus "`experimental world"' effect is often discussed in terms of the \textit{testing effect}, \textit{experimental effect} and the \textit{experimenter effect} as these effects also influence the internal validity of an experiment. Both the testing effect and the experimental effects have been mentioned previously in the section about internal validity.
	
	\bigskip\noindent
	The \textit{experimenter effect} refers to the personal biases of the the reseacher influencing the participants and/or the experiment design in such a way that the results would not be valid outside of the experimental setting. This can be as simple as non-verbal cues while observing the participants, and thus giving them a sort of validation that what they were currently doing was correct. 
	
	
\subsection{Validity and Reliability in the experiment}
	Previously in this chapter we've provided an introduction to some common threats to reliability and validity. This section will try to tie these potensial threats to the experiment conducted during this project. 
	
	\bigskip\noindent
	In the introduction to reliability we mention four key concepts that often are used to describe how reliable an experiment is. The \textit{interrater reliability} is in our case not relevant as is addresses the differences between two researchers rating the participants using qualitative measures. Since this project relies on quantitive data and the only introduction for subjective opinions to contaminate the results was during the scoring process for the pretest and posttest. In order to mitigate this we conducted the scoring process side by side, setting up strict rules for what we would consider a valid answer (e.g $\pm 15^{\circ}$ for tasks involving estimation).
	
	\bigskip\noindent
	The remaining three concepts, \textit{internal consistency}, \textit{equivalence reliability} and \textit{stability reliability}, are however of interest to this project. 
	For a more detailed description of the estimation process we refer you to chapter~\ref{ch:cronbach}, where the results from the pretest and posttest are analysed using Cronbach's alpha and Pearson's product-moment correlations. The result from these analyses showed a alpha value above $0.8$ for the pretest and posttest, above $0.9$ for all the results combined, and a strong positive correlation between the pretest scores and posttest scores. These analyses indicate a high degree of internal consistency and stability.
	
	\bigskip\noindent
	The discussion related to validity is in many ways more complicated then that of reliability as many of the threats to validity can only be verified through being critical towards yourself, and not a scientific analysis. 
	
	\bigskip\noindent
	One of the benefits to validity during this project is the relatively short timespan between the pretest and posttest, which help mitigate several of the threats to validity. This is however a double-edged sword as the short timespan may make some threats more likely to reduce the validity. In our opinion the threats that were most likely to have been interfering with our study are the \textit{testing effect}, \textit{selection bias} and \textit{diffusion between groups}\footnote{We use this as an umbrella term for when participants interact or are affected by eachother}. 
	Some threats that haven't been mentioned during the introduction as \textit{history effects}, \textit{maturation}, etc. have intentionally been overseen as these effects are more likely to happen during longitudinal studies and thus it is very unlikely that they have played a role during this project. 
	
	\bigskip\noindent
	The testing effect, more specificly the learning effect, may however have played a role during experiment as we used the same test for both the pretest and the posttest. In order to mitigate this effect there was not given any feedback on the pretest results to the participants and the pretest was given a week in advance of the experiment itself. We grew more confident that this effect had not played a role in our experiment when comparing the pretest results with the posttest results, as it was seen that the participants in some cases would get a question wrong on the posttest where they had previously answered correctly on the pretest. 
	
	\bigskip\noindent
	Selection bias is also a potensial threat to this study as the groups were put together by the teacher and then randomly assigned to either the robotics group or the simulator group. The analysis in chapter~\ref{ch:independentttest} showed that the pretest mean score of the robotics group were five points higher on average (table~\ref{table:means}). The groups were created by the teachers as at the time when the groups were created we were left with very few students, and any random assignment could possibly skew the distribution of highly skilled participants into one group. It was therefore suggested that the teacher, which have an in-depth knowledge about each participant and who they may work well with. The analyses in part~\ref{part:results} (\nameref{part:results}) shows that the average gain between the groups were very equal if outliers were pruned from the data set. This may indicate that the gains were equals between the group, but it may also indicate that the selection bias promoted more learning in one group over the other. There is no way of determining the effect of this, we therefore urge the reader to keep this fact in the back of the head. 
	
	\bigskip\noindent
	The last big potensial threat indentified to this experiment was the umbrella term \textit{diffusion between group}. This effect may have manifested itself throughout several different ways, it could be simple interactions between the participants in the groups during the break time or during the weekend between the two sessions. Another possibility is that the participants of one group became more motivated or less excited because of the other group, e.g. the participants of the simulator group may have given the little extra in order to show that they should be allowed to use the robot, or (perhaps more likely) they may become demoralized because they were in the simulator group and felt that the robotics group was the better alternative.
	During the sessions we had some indications that some of the participants in the simulator group felt unjustly placed in the simulator group, and thus may not have utilized their full potensial. 
	This was addressed by the teacher with the children after the first sessions, but we are uncertain about how this may have affected the results. 